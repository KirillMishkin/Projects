{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2 task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы) с сайта superjob.ru и hh.ru. Приложение должно анализировать несколько страниц сайта(также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:\n",
    "\n",
    "    *Наименование вакансии\n",
    "    *Предлагаемую зарплату (отдельно мин. и отдельно макс. и отдельно валюта)\n",
    "    *Ссылку на саму вакансию        \n",
    "    *Сайт откуда собрана вакансия\n",
    "    \n",
    "По своему желанию можно добавить еще работодателя и расположение. Данная структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Head Hunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_head_hunter(page, position, vacancy_hh = []):\n",
    "    \"\"\"\n",
    "    В этой функии мы парсим страницы сайта hh\n",
    "    \n",
    "    page: передаем список с номерами страниц и после проверки будем его переводить во множество, \n",
    "          чтобы исключить повторения\n",
    "          \n",
    "          \n",
    "    position: Передаем должность, по которой будем собирать данные  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    main_link = 'https://hh.ru/'\n",
    "\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                            AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "                            Chrome/83.0.4103.116 Safari/537.36'}\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Список для хранения данных по должности \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Перебираем все страницы \n",
    "\n",
    "        \n",
    "    params = {'text':position,\n",
    "                  'L_save_area':True,\n",
    "                 'clusters':True,\n",
    "                 'enable_snippets':True,\n",
    "                  'st':'searchVacancy',\n",
    "                 'fromSearch':True,\n",
    "                 'from':'suggest_post',\n",
    "                  'customDomain':1,\n",
    "                  'page':page-1\n",
    "                 }\n",
    "\n",
    "    html = requests.get(main_link + 'search/vacancy/' , headers = headers, params = params)\n",
    "\n",
    "    soup = bs(html.text,'html.parser')\n",
    "\n",
    "    vacancy_block = soup.find('div',{'class':'vacancy-serp'})\n",
    "\n",
    "    vacancy_list = vacancy_block.find_all('div',{'class':'vacancy-serp-item'})\n",
    "\n",
    "\n",
    "    for i in vacancy_list:\n",
    "        vacancy_dict = {}\n",
    "        vacancy_name = i.find('a',{'class':'bloko-link'}).getText()\n",
    "        vacancy_link = i.find('a',{'class':'bloko-link'})['href']\n",
    "        vacancy_salary = i.find('div',{'class':'vacancy-serp-item__sidebar'}).getText()\n",
    "        vacancy_employer = i.find('div',{'class':'vacancy-serp-item__meta-info'}).getText()\n",
    "        vacancy_city = i.find('span',{'class':'vacancy-serp-item__meta-info'}).getText().split(', ')\n",
    "        vacancy_date = i.find('span',{'class':'vacancy-serp-item__publication-date'}).getText()\n",
    "\n",
    "\n",
    "\n",
    "        currency = vacancy_salary[-4:] # выводим валюту\n",
    "        if not currency:\n",
    "            currency = np.nan\n",
    "        else:\n",
    "            vacancy_salary = vacancy_salary.replace(currency,'') # удаляем валюту\n",
    "\n",
    "\n",
    "        #Проверка метро, если указано метро. то мы его найдем при попощи проверки\n",
    "        # если его нет , то ставим NaN\n",
    "        if len(vacancy_city)>1:\n",
    "            vacancy_metro = vacancy_city[1]\n",
    "        else:\n",
    "            vacancy_metro  = np.nan\n",
    "\n",
    "\n",
    "        # Делаем разделение на минимальную и максимальную ЗП. \n",
    "        # Если где-то не указана сумма ЗП за то мы заполняем значением NaN\n",
    "        if '-' in vacancy_salary:\n",
    "\n",
    "            salaty_split = vacancy_salary.split('-')\n",
    "            salary_min = salaty_split[0].replace(' ','')\n",
    "            salary_max = salaty_split[1].replace(' ','')\n",
    "\n",
    "        elif 'от' in vacancy_salary:\n",
    "\n",
    "            salaty_rep = vacancy_salary.replace('от ','')\n",
    "            salary_min = salaty_rep\n",
    "            salary_max = np.nan\n",
    "\n",
    "        elif 'до' in vacancy_salary:\n",
    "\n",
    "            salaty_rep = vacancy_salary.replace('до ','')\n",
    "            salary_min = np.nan\n",
    "            salary_max = salaty_rep\n",
    "\n",
    "        else:\n",
    "            salary_min = np.nan\n",
    "            salary_max = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        vacancy_dict['vacancy_employer'] = vacancy_employer\n",
    "        vacancy_dict['vacancy_name'] = vacancy_name\n",
    "        vacancy_dict['salary_min'] = salary_min\n",
    "        vacancy_dict['salary_max'] = salary_max\n",
    "        vacancy_dict['currency'] = currency\n",
    "        vacancy_dict['vacancy_city'] = vacancy_city[0]\n",
    "        vacancy_dict['vacancy_date'] = vacancy_date\n",
    "        vacancy_dict['vacancy_link'] = vacancy_link[:vacancy_link.index('?')]\n",
    "\n",
    "\n",
    "        vacancy_hh.append(vacancy_dict)\n",
    "        \n",
    "        \n",
    "    return vacancy_hh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SuperJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_super_job(page, position,vacancy_sj = []): \n",
    "    \n",
    "    \"\"\"\n",
    "    В этой функии мы парсим страницы сайта SJ\n",
    "    \n",
    "    page: передаем множесво с номерами страниц, \n",
    "          чтобы не повторялимь значения и мы не собирали одинаковые данные\n",
    "          \n",
    "    position: Передаем должность, по которой будем собирать данные  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    main_link_sj = 'https://superjob.ru'\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                            AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "                            Chrome/83.0.4103.116 Safari/537.36'}\n",
    "    \n",
    "    \n",
    "        \n",
    "    params = {'keywords':position,\n",
    "                 'page': page}\n",
    "\n",
    "    html_sj = requests.get(main_link_sj+'/vacancy/search/', headers = headers, params = params)\n",
    "\n",
    "    soup = bs(html_sj.text,'html.parser')\n",
    "\n",
    "    vacancy_block = soup.find('div',{'class':'_1ID8B'})\n",
    "\n",
    "    vacancy_list = vacancy_block.find_all('div',{'class':'Fo44F'})\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    for i in vacancy_list:\n",
    "        vacancy_dict = {}\n",
    "\n",
    "        vacancy_name = i.find('div',{'class':'_3mfro'}).getText()\n",
    "        vacancy_link = i.find('a',{'class':'icMQ_'})['href']\n",
    "        vacancy_employer = i.find_all('a',{'class':'icMQ_'})[1].getText()\n",
    "        vacancy_salary = i.find_all('span',{'class':'_3mfro'})[0].getText()\n",
    "        vacancy_city = i.find_all('span',{'class':'_9fXTd'})[1].getText()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if 'По дого' in vacancy_salary:\n",
    "            currency = np.nan\n",
    "        else:\n",
    "            currency = vacancy_salary[-4:] # выводим валюту\n",
    "            vacancy_salary = vacancy_salary.replace(currency,'') # удаляем валюту   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if '—' in vacancy_salary:\n",
    "            salaty_split = vacancy_salary.split('—')\n",
    "            salary_min = salaty_split[0]\n",
    "            salary_max = salaty_split[1]\n",
    "        elif 'от\\xa0' in vacancy_salary:\n",
    "            salaty_rep = vacancy_salary.replace('от\\xa0','')\n",
    "            salary_min = salaty_rep\n",
    "            salary_max = np.nan\n",
    "        elif 'до\\xa0' in vacancy_salary:\n",
    "            salaty_rep = vacancy_salary.replace('до\\xa0','')\n",
    "            salary_min = np.nan\n",
    "            salary_max = salaty_rep\n",
    "        else:\n",
    "            salary_min = np.nan\n",
    "            salary_max = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        vacancy_date = vacancy_city.split(' • ')[0]\n",
    "        vacancy_metro = np.nan\n",
    "\n",
    "        if len(vacancy_city.split(' • ')) == 1:\n",
    "            vacancy_city = [np.nan]\n",
    "\n",
    "        elif len(vacancy_city.split(' • ')) == 2:\n",
    "            vacancy_city = vacancy_city.split(' • ')[1].split(', ')\n",
    "                \n",
    "\n",
    "        vacancy_dict['vacancy_employer'] = vacancy_employer\n",
    "        vacancy_dict['vacancy_name'] = vacancy_name\n",
    "        vacancy_dict['salary_min'] = salary_min\n",
    "        vacancy_dict['salary_max'] = salary_max\n",
    "        vacancy_dict['currency'] = currency\n",
    "        vacancy_dict['vacancy_city'] = vacancy_city[0]\n",
    "        vacancy_dict['vacancy_date'] = vacancy_date\n",
    "        vacancy_dict['vacancy_link'] = main_link_sj+vacancy_link\n",
    "\n",
    "\n",
    "\n",
    "        vacancy_sj.append(vacancy_dict)\n",
    "    \n",
    "    return vacancy_sj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возможные страницы для поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_number_page_SJ(number, position):\n",
    "    \n",
    "    \"\"\"\n",
    "    Возвращает максимальное количество страниц на сайте. \n",
    "    если страница одна , то блока со страницами нет, тогда возвраащет [1] \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    main_link_sj = 'https://superjob.ru'\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                            AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "                            Chrome/83.0.4103.116 Safari/537.36'}\n",
    "    vacancy_sj = []\n",
    "\n",
    "        \n",
    "    params = {'keywords':position}\n",
    "\n",
    "    html_sj = requests.get(main_link_sj+'/vacancy/search/', headers = headers, params = params)\n",
    "\n",
    "    soup = bs(html_sj.text,'html.parser')\n",
    "    \n",
    "    count_block = soup.find('div',{'class':'L1p51'})\n",
    "    \n",
    "    if count_block:\n",
    "\n",
    "        max_count_list = count_block.find_all('span',{'class':'_3IDf-'})[-2].getText()\n",
    "    else:\n",
    "        return np.array(1)\n",
    "\n",
    "    return np.arange(1,int(max_count_list)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_number_page_HH(number, position):\n",
    "    \n",
    "    \n",
    "    \"\"\"\"\n",
    "    Возвращает максимальное количество страниц на сайте. \n",
    "    если страница одна , то блока со страницами нет, тогда возвраащет [1] \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    main_link_hh = 'https://hh.ru/'\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                            AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "                            Chrome/83.0.4103.116 Safari/537.36'}\n",
    "\n",
    "\n",
    "\n",
    "    params = {'text':position,\n",
    "             'area':1,\n",
    "              'L_save_area':True,\n",
    "             'clusters':True,\n",
    "             'enable_snippets':True,\n",
    "              'st':'searchVacancy',\n",
    "             'fromSearch':True,\n",
    "             'from':'suggest_post',\n",
    "              'customDomain':1,\n",
    "              'page':number-1\n",
    "             }\n",
    "    \n",
    "    html = requests.get(main_link_hh + 'search/vacancy/' , headers = headers, params = params)\n",
    "\n",
    "    soup = bs(html.text,'html.parser')\n",
    "\n",
    "    count_block = soup.find('div',{'data-qa':'pager-block'})\n",
    "    \n",
    "    if count_block:\n",
    "        \n",
    "        max_count_list = count_block.find_all('a',{'class':'bloko-button'})[-2].getText()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        return np.array(1)\n",
    "    \n",
    "\n",
    "    return np.arange(1,int(max_count_list)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_set_all(value_1, value_2):\n",
    "    \n",
    "    \"\"\"\n",
    "        Функция сделана для преобразование и объединения DataSet \n",
    "        настройка индексов и преобразование зарплаты в тип int\n",
    "        Делаем переименование столбцов и добавляем сайт , откуда был собран материал \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_1 = pd.DataFrame(value_1)\n",
    "    \n",
    "    df_2 = pd.DataFrame(value_2)\n",
    "    \n",
    "    df = pd.concat((df_1, df_2))\n",
    "    \n",
    "    df['website'] = 'www.'+df['vacancy_link'].str.extract(\"(\\w+)\\.\")+'.ru'\n",
    "    \n",
    "    df = df.rename(columns = {'vacancy_employer':'Работодатель',\n",
    "         'vacancy_name':'Вакансия',\n",
    "         'salary_min':'Зарплата_от',\n",
    "         'salary_max':'Зарплата_до',\n",
    "         'vacancy_city':'Город',\n",
    "         'vacancy_date':'Дата_публикации',\n",
    "         'vacancy_link':'Ссылка_на_вакансию',\n",
    "          'website':'Сайт',\n",
    "            'currency':'Валюта'})\n",
    "    \n",
    "    df = df.reset_index().drop('index',axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.loc[df['Зарплата_от'].isnull(), 'Зарплата_от'] = '0'\n",
    "    df.loc[df['Зарплата_до'].isnull(), 'Зарплата_до'] = '0'\n",
    "    \n",
    "#     df['Зарплата_от'] = df['Зарплата_от'].str.replace('\\xa0','').astype(int)\n",
    "#     df['Зарплата_до'] = df['Зарплата_до'].str.replace('\\xa0','').astype(int)\n",
    "    \n",
    "    df.style.highlight_null(null_color='red')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Должность "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Введите должность, напрмиер Аналитик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите должность: Менеджер\n"
     ]
    }
   ],
   "source": [
    "position = input('Введите должность: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор данных c HeadHunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pages_hh = max_number_page_HH(1,position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Страницы для поиска на hh.ru: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40]\n",
      "\n",
      "\n",
      "(Введите страницы через пробел или одну страницу)\n",
      "С каких страниц собираем данные? hh.ru: 1 2 3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'getText'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-88d48297e35c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_page_hh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_pages_hh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mmy_data_hh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_head_hunter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_page_hh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;31m# все страницы , которые мы прошли по поиску удаляем их основного списка\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mmy_pages_hh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmy_pages_hh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber_page_hh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-10adc1b89119>\u001b[0m in \u001b[0;36mparse_head_hunter\u001b[1;34m(page, position, vacancy_hh)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mvacancy_employer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'vacancy-serp-item__meta-info'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mvacancy_city\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'span'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'vacancy-serp-item__meta-info'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m', '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mvacancy_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'span'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'vacancy-serp-item__publication-date'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'getText'"
     ]
    }
   ],
   "source": [
    "print(f'Страницы для поиска на hh.ru: {my_pages_hh}\\n')\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    pages_hh = np.array(input('(Введите страницы через пробел или одну страницу)\\nС каких страниц собираем данные? hh.ru: ').split()).astype(int)\n",
    "    \n",
    "    \n",
    "    # Преобразуем все нулевые значения в 1. на hh страницы начинаеются с 0. в условие нижу есть page - 1. \n",
    "    # так удобней для расчета\n",
    "    \n",
    "    for i in range(len(pages_hh)):\n",
    "        if pages_hh[i] == 0:\n",
    "            pages_hh[i] = 1\n",
    "    \n",
    "    \n",
    "    if pages_hh.size == 0:\n",
    "        continue\n",
    "    \n",
    "    count_false = 0 # Счетчик страниц которых нет в списке\n",
    "\n",
    "    \n",
    "    # Делаем пеербор по страницам , которые ввели для поиска и сравниваем их со страницами, которые отобразились на сайте.\n",
    "    \n",
    "    for number_page_hh in pages_hh:\n",
    "\n",
    "        if np.in1d(number_page_hh, my_pages_hh):\n",
    "\n",
    "            my_data_hh = parse_head_hunter(number_page_hh,position)\n",
    "            # все страницы , которые мы прошли по поиску удаляем их основного списка\n",
    "            my_pages_hh = np.setdiff1d([my_pages_hh],number_page_hh)\n",
    "        else:\n",
    "            # если страницы нет, то работате счетчик. И если он равен размену введенных страниц, то выдается ошибка. СМ ниже\n",
    "            count_false+=1\n",
    "            \n",
    "    if count_false == pages_hh.size:\n",
    "        \n",
    "        print('Указаны страницы, которых нет или уже проверена')\n",
    "        print()\n",
    "        \n",
    "        no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "        # Делаем првоерку на продолжение по программе. \n",
    "        while (no_or_yes != 'y') and (no_or_yes !='n'):\n",
    "            \n",
    "            print('Не корректный ввод')\n",
    "            print()\n",
    "            \n",
    "            no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        if no_or_yes == 'y':\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "            \n",
    "    print(f'Оставшиеся страницы для парсинга: {my_pages_hh}')\n",
    "    # пока массив со страницами не равен 0 у нас есть возможность собрать еще данные или закончить\n",
    "    if my_pages_hh.size != 0:\n",
    "        \n",
    "        no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        while (no_or_yes != 'y') and (no_or_yes !='n'):\n",
    "            \n",
    "            print('Не корректный ввод')\n",
    "            print()\n",
    "            \n",
    "            no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        if no_or_yes == 'y':\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        # страниц для парсинга не осталось, заканчиваем цикл и выходим\n",
    "        print('Страниц для парсинга не осталось')\n",
    "        print()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор данных c SuperJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pages_sj = max_number_page_SJ(1,position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Страницы для парсинга на superjob.ru: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62]\n",
      "\n",
      "(Введите страницы через пробел или одну страницу)\n",
      "С каких страниц собираем данные? superjob.ru: 1 2 3\n",
      "Оставшиеся страницы для парсинга: [ 4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n",
      " 52 53 54 55 56 57 58 59 60 61 62]\n",
      "\n",
      "Продолжить парсинг? y/n: n\n"
     ]
    }
   ],
   "source": [
    "print(f'Страницы для парсинга на superjob.ru: {my_pages_sj}')\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    pages_sj = np.array(input('(Введите страницы через пробел или одну страницу)\\nС каких страниц собираем данные? superjob.ru: ').split()).astype(int)\n",
    "    \n",
    "     # Преобразуем все нулевые значения в 1. на hh страницы начинаеются с 0. в условие нижу есть page - 1. \n",
    "    # так удобней для расчета\n",
    "    for i in range(len(pages_sj)):\n",
    "        if pages_sj[i] == 0:\n",
    "            pages_sj[i] = 1\n",
    "\n",
    "    \n",
    "    if pages_sj.size == 0:\n",
    "        continue\n",
    "    \n",
    "    count_false = 0\n",
    "\n",
    "    for number_page_sj in pages_sj:\n",
    "\n",
    "        if np.in1d(number_page_sj, my_pages_sj):\n",
    "\n",
    "            my_data_sj = parse_super_job(number_page_sj,position)\n",
    "            # все страницы , которые мы прошли по поиску удаляем их основного списка\n",
    "            my_pages_sj = np.setdiff1d([my_pages_sj],number_page_sj)\n",
    "        else:\n",
    "            # если страницы нет, то работате счетчик. И если он равен размену введенных страниц, то выдается ошибка. СМ ниже\n",
    "            count_false+=1\n",
    "            \n",
    "    if count_false == pages_sj.size:\n",
    "        \n",
    "        print('Указаны страницы, которых нет или уже проверена Вот тутн')\n",
    "        print()\n",
    "        \n",
    "        no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "        # Делаем првоерку на продолжение по программе. \n",
    "        while (no_or_yes != 'y') and (no_or_yes !='n'):\n",
    "            \n",
    "            print('Не корректный ввод')\n",
    "            print()\n",
    "            \n",
    "            no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        if no_or_yes == 'y':\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "            \n",
    "    print(f'Оставшиеся страницы для парсинга: {my_pages_sj}')\n",
    "    print()\n",
    "    # пока массив со страницами не равен 0 у нас есть возможность собрать еще данные или закончить\n",
    "    if my_pages_sj.size != 0:\n",
    "        \n",
    "        no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        while (no_or_yes != 'y') and (no_or_yes !='n'):\n",
    "            \n",
    "            print('Не корректный ввод')\n",
    "            print()\n",
    "            \n",
    "            no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        if no_or_yes == 'y':\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        # страниц для парсинга не осталось, заканчиваем цикл и выходим\n",
    "        print('Страниц для парсинга не осталось, данные собраны')\n",
    "        print()\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = df_set_all(my_data_hh, my_data_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Сайт\n",
       "www.hh.ru          50\n",
       "www.superjob.ru    60\n",
       "Name: Ссылка_на_вакансию, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.groupby('Сайт')['Ссылка_на_вакансию'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "руб.    74\n",
       "NaN     34\n",
       " USD     2\n",
       "Name: Валюта, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df['Валюта'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Работодатель</th>\n",
       "      <th>Вакансия</th>\n",
       "      <th>Зарплата_от</th>\n",
       "      <th>Зарплата_до</th>\n",
       "      <th>Валюта</th>\n",
       "      <th>Город</th>\n",
       "      <th>Дата_публикации</th>\n",
       "      <th>Ссылка_на_вакансию</th>\n",
       "      <th>Сайт</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ООО Your Suit</td>\n",
       "      <td>Руководитель отдела продаж / Директор по продажам</td>\n",
       "      <td>130 000</td>\n",
       "      <td>250 000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>28 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37713537</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alphaopen</td>\n",
       "      <td>Бизнес-аналитик программного решения</td>\n",
       "      <td>160 000</td>\n",
       "      <td>220 000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>26 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37694581</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ООО Банкирро</td>\n",
       "      <td>Ведущий менеджер по продажам</td>\n",
       "      <td>170 000</td>\n",
       "      <td>210 000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>26 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37229320</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NodaSoft</td>\n",
       "      <td>IT Analist (Moscow)</td>\n",
       "      <td>120 000</td>\n",
       "      <td>0</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>28 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37715080</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Банк ВТБ (ПАО)</td>\n",
       "      <td>Стажер ВТБ IT-Юниор (Аналитика, разработка, De...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Москва</td>\n",
       "      <td>28 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37595281</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Ваш офис плюс</td>\n",
       "      <td>Менеджер по продажам</td>\n",
       "      <td>50 000</td>\n",
       "      <td>60 000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>9:22</td>\n",
       "      <td>https://superjob.ru/vakansii/menedzher-po-prod...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Буду Говорить</td>\n",
       "      <td>Менеджер по работе с клиентами</td>\n",
       "      <td>50 000</td>\n",
       "      <td>0</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>9:21</td>\n",
       "      <td>https://superjob.ru/vakansii/menedzher-po-rabo...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ООО «Оптима Сервис»</td>\n",
       "      <td>Менеджер проектов</td>\n",
       "      <td>45 000</td>\n",
       "      <td>0</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>9:21</td>\n",
       "      <td>https://superjob.ru/vakansii/menedzher-proekto...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Окна Стрит</td>\n",
       "      <td>Менеджер по запуску заказов в производство (ок...</td>\n",
       "      <td>60 000</td>\n",
       "      <td>70 000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>9:18</td>\n",
       "      <td>https://superjob.ru/vakansii/menedzher-po-zapu...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Федеральная сеть книжных магазинов «Читай-город»</td>\n",
       "      <td>Менеджер интернет-заказов</td>\n",
       "      <td>30 000</td>\n",
       "      <td>36 000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>9:16</td>\n",
       "      <td>https://superjob.ru/vakansii/menedzher-interne...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Работодатель  \\\n",
       "0                                      ООО Your Suit    \n",
       "1                                          Alphaopen    \n",
       "2                                       ООО Банкирро    \n",
       "3                                           NodaSoft    \n",
       "4                                     Банк ВТБ (ПАО)    \n",
       "..                                                ...   \n",
       "105                                     Ваш офис плюс   \n",
       "106                                     Буду Говорить   \n",
       "107                               ООО «Оптима Сервис»   \n",
       "108                                        Окна Стрит   \n",
       "109  Федеральная сеть книжных магазинов «Читай-город»   \n",
       "\n",
       "                                              Вакансия Зарплата_от  \\\n",
       "0    Руководитель отдела продаж / Директор по продажам     130 000   \n",
       "1                 Бизнес-аналитик программного решения     160 000   \n",
       "2                         Ведущий менеджер по продажам     170 000   \n",
       "3                                  IT Analist (Moscow)    120 000    \n",
       "4    Стажер ВТБ IT-Юниор (Аналитика, разработка, De...           0   \n",
       "..                                                 ...         ...   \n",
       "105                               Менеджер по продажам     50 000    \n",
       "106                     Менеджер по работе с клиентами     50 000    \n",
       "107                                  Менеджер проектов     45 000    \n",
       "108  Менеджер по запуску заказов в производство (ок...     60 000    \n",
       "109                          Менеджер интернет-заказов     30 000    \n",
       "\n",
       "    Зарплата_до Валюта   Город Дата_публикации  \\\n",
       "0       250 000   руб.  Москва         28 июня   \n",
       "1       220 000   руб.  Москва         26 июня   \n",
       "2       210 000   руб.  Москва         26 июня   \n",
       "3             0   руб.  Москва         28 июня   \n",
       "4             0    NaN  Москва         28 июня   \n",
       "..          ...    ...     ...             ...   \n",
       "105     60 000    руб.  Москва            9:22   \n",
       "106           0   руб.  Москва            9:21   \n",
       "107           0   руб.  Москва            9:21   \n",
       "108     70 000    руб.  Москва            9:18   \n",
       "109     36 000    руб.  Москва            9:16   \n",
       "\n",
       "                                    Ссылка_на_вакансию             Сайт  \n",
       "0                       https://hh.ru/vacancy/37713537        www.hh.ru  \n",
       "1                       https://hh.ru/vacancy/37694581        www.hh.ru  \n",
       "2                       https://hh.ru/vacancy/37229320        www.hh.ru  \n",
       "3                       https://hh.ru/vacancy/37715080        www.hh.ru  \n",
       "4                       https://hh.ru/vacancy/37595281        www.hh.ru  \n",
       "..                                                 ...              ...  \n",
       "105  https://superjob.ru/vakansii/menedzher-po-prod...  www.superjob.ru  \n",
       "106  https://superjob.ru/vakansii/menedzher-po-rabo...  www.superjob.ru  \n",
       "107  https://superjob.ru/vakansii/menedzher-proekto...  www.superjob.ru  \n",
       "108  https://superjob.ru/vakansii/menedzher-po-zapu...  www.superjob.ru  \n",
       "109  https://superjob.ru/vakansii/menedzher-interne...  www.superjob.ru  \n",
       "\n",
       "[110 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
